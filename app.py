import os
import tempfile
import logging
import re
from flask import Flask, render_template, request, jsonify
from dotenv import load_dotenv
from faster_whisper import WhisperModel
import openai
import random

load_dotenv()

# Load the faster-whisper model once at startup
whisper_model = WhisperModel("base.en", device="cpu", compute_type="int8")

app = Flask(__name__)

# Configure logging to file for debugging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.FileHandler("app.log"),
        logging.StreamHandler()
    ],
)

logger = logging.getLogger(__name__)


def generate_sentence_gpt() -> str | None:
    """Return a short English sentence generated by GPT-3.5.

    Returns ``None`` if ``OPENAI_API_KEY`` isn't configured or the request
    fails.
    """
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        logger.warning("OPENAI_API_KEY not set; using fallback sentences")
        return None

    client = openai.OpenAI(api_key=api_key)
    try:
        resp = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": (
                        "You help learners practice pronunciation by providing short and varied sentences."
                    ),
                },
                {
                    "role": "user",
                    "content": "Give me one short, unique English sentence.",
                },
            ],
            max_tokens=20,
            temperature=1.0,
            presence_penalty=0.6,
        )
        sentence = resp.choices[0].message.content.strip()
        logger.info("Generated sentence with GPT: %s", sentence)
        return sentence
    except Exception:
        logger.exception("Failed to generate sentence with OpenAI")
        return None


def transcribe_audio(audio_path: str):
    """Transcribe the full audio file and return words with probabilities."""
    logger.info("Transcribing with faster-whisper")
    segments, _ = whisper_model.transcribe(
        audio_path,
        word_timestamps=True,
        beam_size=5,
    )

    words = []
    for segment in segments:
        for word in segment.words:
            prob = getattr(word, "probability", None)
            clean = re.sub(r"^[^\w']+|[^\w']+$", "", word.word).lower()
            words.append({"word": word.word, "clean": clean, "prob": prob})

    text = " ".join(w["word"] for w in words)
    return text, words

@app.route("/")
def home():
    return render_template("index.html")

@app.route("/transcribe", methods=["POST"])
def transcribe():
    file = request.files["audio"]  # speech.webm
    logger.info("Received transcription request")

    with tempfile.NamedTemporaryFile(delete=False, suffix=".webm") as tmp:
        file.save(tmp.name)
        text, words = transcribe_audio(tmp.name)
        os.remove(tmp.name)

    logger.info("Transcription completed")

    return jsonify({"text": text, "words": words})

@app.route("/random-sentence")
def random_sentence():
    sentence = generate_sentence_gpt()
    if not sentence:
        with open("static/sentences.txt", "r", encoding="utf-8") as f:
            lines = [line.strip() for line in f if line.strip()]
        sentence = random.choice(lines)
    return jsonify({"sentence": sentence})


if __name__ == "__main__":
    app.run(debug=True, host="0.0.0.0", port=5000)

